{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31000fb8",
   "metadata": {},
   "source": [
    "SCC0270 - Redes Neurais e Aprendizado Profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cbe4e",
   "metadata": {},
   "source": [
    "Alunos:\n",
    "- 10716504 - Helbert Moreira Pinto\n",
    "- 10377708 - João Marcos Della Torre Divino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51582898",
   "metadata": {},
   "source": [
    "Exercicio 1 - Implementar e treinar o modelo Adaline para reconhecer os símbolos Y e Y invertido (letra “Y” e letra “Y” invertida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e311d39",
   "metadata": {},
   "source": [
    "Inicialmente construimos, a partir de matrizes de ordem 5, modelos graficos para os conjuntos de \"Y\" e de \"Y invertido\" utilizando o valor 1 para células com conteúdo e -1 para representar a falta de conteúdo.  \n",
    "Abaixo vemos imagens dos modelos elaborados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6269718",
   "metadata": {},
   "source": [
    "<img src='imgs/y.jpeg' alt='Y' width='500'/> <img src='imgs/y_inv.jpeg' alt='Y invertido' width='500'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b4fcd",
   "metadata": {},
   "source": [
    "Para estruturar melhor o projeto, decidimos por criar um gerador de modelos, em que podemos parametrizar o tamanho do conjunto gerado e o limite máximo de ruído por amostra.  \n",
    "Note que não é problema se quisermos gerar um conjunto maior que o numero de modelos, visto que ao inserirmos um ruído aleatorio as amostras ficam levemente diferenciadas.\n",
    "\n",
    "```python\n",
    "gerar_dados(n=100, num_ruido=3)\n",
    "```\n",
    "No exemplo acima estamos gerando um conjunto de dados com 100 amostras e com até 3 células de ruído por amostra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b4894",
   "metadata": {},
   "source": [
    "Por exemplo, dado o modelo a seguir:  \n",
    "![Modelo](modelos/3.png)  \n",
    "\n",
    "Temos o caso onde foi aplicado ruído em até 3 células, gerando as seguintes derivações:  \n",
    "![Ruido 1](gerados/exec_2/img_11_modelo_3_ruido_0_10_17.png) \n",
    "![Ruido 2](gerados/exec_2/img_68_modelo_3_ruido_12_11.png)\n",
    "![Ruido 3](gerados/exec_2/img_90_modelo_3_ruido_20.png)\n",
    "![Ruido 3](gerados/exec_2/img_81_modelo_3_ruido_16_23_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9455ab60",
   "metadata": {},
   "source": [
    "O conjunto de dados gerado possui o seguinte formato por amostra:  \n",
    "- 1 coluna para entrada do bias, sempre com o valor 1\n",
    "- 25 colunas que representam variaveis explicativas (vetor X) que podem ter o valor 1 ou -1, conforme o modelo e o ruído aplicado\n",
    "- 1 coluna que representa o label (ou variavel resposta - valor Y), que pode ser 1 para o caso do modelo ser do conjunto \"Y\" ou -1 para o caso do modelo ser do conjunto \"Y invertido\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e9923",
   "metadata": {},
   "source": [
    "Na construção do perceptron, utilizamos a orientação a objetos presente na linguagem Python para melhor organizar o codigo.  \n",
    "\n",
    "![Perceptron](imgs/perceptron.png)\n",
    "\n",
    "Na figura acima vemos o modelo teórico do perceptron, onde basicamente temos uma saída composta da seguinte equação:  \n",
    "$$ y_k = \\theta_k + \\sum_{i=1}^{N} x_{ki} * w_i $$  \n",
    "onde:  \n",
    "- $y_k$ é a saida calculada\n",
    "- $x_k$ é o vetor de variaveis explicativas\n",
    "- $\\theta_k$ é o limiar de ativação (bias)\n",
    "\n",
    "Na implementação utilzamos como função de ativação o degrau bipolar:\n",
    "```python\n",
    "# degrau bipolar\n",
    "def funcao_ativacao(u):\n",
    "    return -1 if u <= 0 else 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460b917",
   "metadata": {},
   "source": [
    "No treino do perceptron, iniciamos os pesos com valores aleatorios, que são ajustados a cada iteração do algoritmo.  \n",
    "Mais especificamente, mantêm na mesma instância até que os pesos sejam ajustados de maneira a produzir a saída esperada.  \n",
    "\n",
    "```python\n",
    "def treinar(data):\n",
    "    # algoritmo so acaba qnd o erro em todas as amostras de treino = 0\n",
    "    while True:\n",
    "        epoca += 1\n",
    "        erro_epoca = 0\n",
    "        \n",
    "        for i in data.index:\n",
    "            # X = variaveis explicativas\n",
    "            # Y = variavel resposta da instancia\n",
    "            X = [x for x in data.loc[i, data.columns != 'y']]\n",
    "            Y = data['y'][i]\n",
    "            \n",
    "            # continua enquanto nao prever corretamente a instancia atual\n",
    "            while True:\n",
    "                # y = previsao realizada para amostra atual\n",
    "                # Y = valor esperado\n",
    "                y = prever(X)\n",
    "                erro_amostra = comparar(Y, y)\n",
    "                if erro_amostra == 0:\n",
    "                    break\n",
    "                    \n",
    "                # se valor previsto != esperado, atualiza os pesos\n",
    "                # delta w = taxa aprendizagem * erro de previsao * vetor de entradas\n",
    "                delta_w = np.dot((taxa_aprendizagem * erro_amostra), X)\n",
    "                w += delta_w\n",
    "                erro_epoca += abs(erro_amostra)\n",
    "        \n",
    "        if erro_epoca == 0:\n",
    "            break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f41ba1",
   "metadata": {},
   "source": [
    "Para realizar vários treinamentos alterando apenas os hiperparâmetros, criamos a função abaixo que realiza todo o processamento:\n",
    "- geração do conjunto de dados \n",
    "- separação do conjunto entre dados de treino e dados de teste\n",
    "- treinamento do perceptron\n",
    "- utiliza os pesos treinados obtidos para os aplicar no conjunto de testes\n",
    "- calcula a taxa de acerto/erro (acurácia) na etapa de testes\n",
    "\n",
    "Ao executar o código várias vezes com conjuntos de treino/teste diferentes, temos uma estimativa média da acurácia do perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7380bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando classe Perceptron criada no projeto\n",
    "from src.perceptron import Perceptron\n",
    "from src.modelos import gerar_dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "\n",
    "# função que separa randomicamente os dados em treino/teste\n",
    "# realiza o processo de aprendizagem com os dados de treino\n",
    "# calcula a acuracia nos dados de teste\n",
    "def executar(n_amostras=50, tam_ruido=5, n_testes=100, treino_teste=0.8, taxa_aprend=0.5):\n",
    "    \n",
    "    # gera os dados que sera utilizado no processamento\n",
    "    df = gerar_dados(n=n_amostras, num_ruido=tam_ruido)\n",
    "\n",
    "    soma_acuracia = 0\n",
    "    for rodada in range(n_testes):\n",
    "        # utilizando randomicamente uma seed por rodada\n",
    "        seed = randint(1, 999999)\n",
    "\n",
    "        # separando aleatoriamente o conjunto de dados\n",
    "        df_teste, df_treino = train_test_split(df, test_size=treino_teste, shuffle=True, stratify=df['y'], random_state=seed)\n",
    "\n",
    "        # treino\n",
    "        p = Perceptron(n_entradas=len(df.columns)-2, tx=taxa_aprend, seed=seed)\n",
    "        p.treinar(df_treino)\n",
    "\n",
    "        # teste\n",
    "        n = 0\n",
    "        for i in df_teste.index:\n",
    "            X = [x for x in df_teste.loc[i, df_teste.columns != 'y']]\n",
    "            Y = df_teste['y'][i]\n",
    "            y = p.prever(X)\n",
    "            n += 1 if Y == y else 0\n",
    "        \n",
    "        acuracia = n/len(df_teste)\n",
    "        soma_acuracia += acuracia\n",
    "    \n",
    "    if n_testes > 0:\n",
    "        print('Acuracia Media: {:.2f}%'.format(100*(soma_acuracia/n_testes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5390e4c7",
   "metadata": {},
   "source": [
    "Os seguintes casos de teste foram realizados, utilizando valores diferentes para os hiperparâmetros para ilustrar alguns possíveis comportamentos do perceptron:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3653726",
   "metadata": {},
   "source": [
    "CASO 1 - Underfit  \n",
    "\n",
    "Quando nosso número de amostras no conjunto de treino é muito reduzido ou quando as variáveis explicativas não conseguem descrever bem as caracteristicas (muito ruído nos dados), temos o caso onde o perceptron não consegue identificar padrões que mostrem os distintos conjuntos, e portanto a taxa de acertos no conjunto de teste tende a ser menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d06f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 78.60%\n"
     ]
    }
   ],
   "source": [
    "# ruido de ate 7 celulas por amostra, ou seja, variavel X explica pouco o conjunto\n",
    "amostras = 100\n",
    "ruido = 12\n",
    "testes = 50\n",
    "treino = 0.8\n",
    "taxa = 1\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13bb9e",
   "metadata": {},
   "source": [
    "CASO 2 - Overfit  \n",
    "\n",
    "Opostamente ao underfit, quando tentamos ajustar demais os pesos aos dados de treino o algoritmo \"decora\" a resposta para as entradas, e como no caso anterior, a taxa de acertos tende a cair quando o modelo é exposto aos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1ceec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 92.90%\n"
     ]
    }
   ],
   "source": [
    "# taxa de aprendizagem extremamente baixa, ou seja, os pesos são lentamente ajustados aos dados de treino\n",
    "amostras = 100\n",
    "ruido = 5\n",
    "testes = 50\n",
    "treino = 0.8\n",
    "taxa = 0.00001\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d00966",
   "metadata": {},
   "source": [
    "CASO 3 - Ajustado  \n",
    "\n",
    "O modelo ideial é quando os hiperparâmetros são ajustados de modo que o modelo identifique as particularidades dos conjuntos sem que esteja sobreajustado à um conjunto específico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26473e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 99.20%\n"
     ]
    }
   ],
   "source": [
    "amostras = 100\n",
    "ruido = 3\n",
    "testes = 50\n",
    "treino = 0.8\n",
    "taxa = 0.1\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
