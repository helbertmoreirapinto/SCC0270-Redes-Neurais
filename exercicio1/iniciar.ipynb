{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31000fb8",
   "metadata": {},
   "source": [
    "SCC0270 - Redes Neurais e Aprendizado Profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507cbe4e",
   "metadata": {},
   "source": [
    "Alunos:\n",
    "- 10716504 - Helbert Moreira Pinto\n",
    "- 10377708 - João Marcos Della Torre Divino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51582898",
   "metadata": {},
   "source": [
    "Exercicio 1 - Implementar e treinar o modelo Adaline para reconhecer os símbolos Y e Y invertido (letra “Y” e letra “Y” invertida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e311d39",
   "metadata": {},
   "source": [
    "Inicialmente construimos, a partir de matrizes de ordem 5, modelos graficos para os conjuntos de \"Y\" e de \"Y invertido\" utilizando o valor 1 para células com conteudo e -1 para representar a falta de conteudo.  \n",
    "Abaixo vemos imagens dos modelos elaborados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6269718",
   "metadata": {},
   "source": [
    "![Modelos Y](imgs/y.png)   ![Modelos Y Invertido](imgs/y_inv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b4fcd",
   "metadata": {},
   "source": [
    "Para estruturar melhor o projeto, decidimos por criar um gerador de modelos em que podemos parametrizar o tamanho do conjunto gerado bem como o limite maximo de ruido por amostra.  \n",
    "Note não é problema se quisermos gerar um conjunto maior que o numero de modelos, visto que ao inserirmos um ruido aleatorio as amostras ficam levemente diferenciadas.\n",
    "\n",
    "```python\n",
    "gerar_dados(n=100, num_ruido=3)\n",
    "```\n",
    "No exemplo acima estamos gerando um conjunto de dados com 100 amostras e com até 3 celulas de ruido por amostra.\n",
    "\n",
    "O conjunto de dados gerado possui o seguinte formato por amostra:  \n",
    "- 1 coluna para entrada do bias, sempre com o valor 1\n",
    "- 25 colunas que representam variaveis explicativas (vetor X) que podem ter o valor 1 ou -1, conforme o modelo e o ruido aplicado\n",
    "- 1 coluna que representa o label (ou variavel resposta - valor Y), que pode ser 1 para o caso do modelo ser do conjunto \"Y\" ou -1 para o caso do modelo ser do conjunto \"Y invertido\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e9923",
   "metadata": {},
   "source": [
    "Na construção do perceptron, utilizamos a orientação a objetos presente na linguagem Python para melhor organizar o codigo.  \n",
    "\n",
    "![Perceptron](imgs/perceptron.png)\n",
    "\n",
    "Na figura acima vemos o modelo teorico do perceptron, onde basicamente temos uma saida composta da seguinte equação:  \n",
    "$$ y_k = \\sum_{i=0}^{N} x_{ki} * w_i + \\theta_k $$  \n",
    "onde:  \n",
    "- $y_k$ é a saida calculada\n",
    "- $x_k$ é o vetor de variaveis explicativas\n",
    "- $\\theta_k$ é o limiar de ativação (bias)\n",
    "\n",
    "Na implementação utilzamos como função de ativação o degrau bipolar\n",
    "```python\n",
    "# degrau bipolar\n",
    "def funcao_ativacao(u):\n",
    "    return -1 if u <= 0 else 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0460b917",
   "metadata": {},
   "source": [
    "No treino do perceptron, iniciamos os pesos com valores aleatorios, que são ajustados a cada iteração do algoritmo  \n",
    "```python\n",
    "def treinar(data):\n",
    "    # algoritmo so acaba qnd o erro em todas as amostras de treino = 0\n",
    "    while True:\n",
    "        epoca += 1\n",
    "        erro_epoca = 0\n",
    "        \n",
    "        for i in data.index:\n",
    "            # X = variaveis explicativas\n",
    "            # Y = variavel resposta da instancia\n",
    "            X = [x for x in data.loc[i, data.columns != 'y']]\n",
    "            Y = data['y'][i]\n",
    "            \n",
    "            # continua enquanto nao prever corretamente a instancia atual\n",
    "            while True:\n",
    "                # y = previsao realizada para amostra atual\n",
    "                # Y = valor esperado\n",
    "                y = prever(X)\n",
    "                erro_amostra = comparar(Y, y)\n",
    "                if erro_amostra == 0:\n",
    "                    break\n",
    "                    \n",
    "                # se valor previsto != esperado, atualiza os pesos\n",
    "                # delta w = taxa aprendizagem * erro de previsao * vetor de entradas\n",
    "                delta_w = np.dot((taxa_aprendizagem * erro_amostra), X)\n",
    "                w += delta_w\n",
    "                erro_epoca += abs(erro_amostra)\n",
    "        \n",
    "        if erro_epoca == 0:\n",
    "            break\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f41ba1",
   "metadata": {},
   "source": [
    "A celula abaixo realiza todo o processamento:\n",
    "- geração do conjunto de dados \n",
    "- separação do conjunto entre dados de treino e dados de teste\n",
    "- treinamento do perceptron\n",
    "- utiliza os pesos treinados no teste para os testes\n",
    "- calcula a taxa de erro/acerto (acurácia) na etapa de testes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7380bd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando classe Perceptron criada no projeto\n",
    "from src.perceptron import Perceptron\n",
    "from src.modelos import gerar_dados\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "\n",
    "# função que separa randomicamente os dados em treino/teste\n",
    "# realiza o processo de aprendizagem com os dados de treino\n",
    "# calcula a acuracia nos dados de teste\n",
    "def executar(n_amostras=50, tam_ruido=5, n_testes=100, treino_teste=0.8, taxa_aprend=0.5):\n",
    "    \n",
    "    # gera os dados que sera utilizado no processamento\n",
    "    df = gerar_dados(n=n_amostras, num_ruido=tam_ruido)\n",
    "\n",
    "    soma_acuracia = 0\n",
    "    for rodada in range(n_testes):\n",
    "        # utilizando randomicamente uma seed por rodada\n",
    "        seed = randint(1, 999999)\n",
    "\n",
    "        # separando aleatoriamente o conjunto de dados\n",
    "        df_teste, df_treino = train_test_split(df, test_size=treino_teste, shuffle=True, stratify=df['y'], random_state=seed)\n",
    "\n",
    "        # treino\n",
    "        p = Perceptron(n_entradas=len(df.columns)-2, tx=taxa_aprend, seed=seed)\n",
    "        p.treinar(df_treino)\n",
    "\n",
    "        # teste\n",
    "        n = 0\n",
    "        for i in df_teste.index:\n",
    "            X = [x for x in df_teste.loc[i, df_teste.columns != 'y']]\n",
    "            Y = df_teste['y'][i]\n",
    "            y = p.prever(X)\n",
    "            n += 1 if Y == y else 0\n",
    "        \n",
    "        acuracia = n/len(df_teste)\n",
    "        soma_acuracia += acuracia\n",
    "\n",
    "    print('Acuracia Media: {:.2f}%'.format(100*(soma_acuracia/n_testes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585df79",
   "metadata": {},
   "source": [
    "CASO 1 - Underfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3653726",
   "metadata": {},
   "source": [
    "Quando nosso numero de amostras no conjunto de treino é muito reduzido ou quando as variaveis explicativas não conseguem descrever bem as caracteristicas, temos o caso onde o perceptron não consegue identificar padrões que identificam os distintos conjuntos, e portanto a taxa de acertos no conjunto de teste tende a cair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d06f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 59.93%\n"
     ]
    }
   ],
   "source": [
    "# ruido de ate 10 celulas por amostra, ou seja, variavel X explica pouco o conjunto\n",
    "amostras = 100\n",
    "ruido = 10 \n",
    "testes = 500\n",
    "treino = 0.1\n",
    "taxa = 1\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313c7a8",
   "metadata": {},
   "source": [
    "CASO 2 - Overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13bb9e",
   "metadata": {},
   "source": [
    "Opostamente ao underfit, quando tentamos ajustar demais os pesos aos dados de treino o algoritmo \"decora\" a resposta para as entradas, e como no caso anterior, a taxa de acertos tende a cair quando o modelo é exposto aos dados de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1ceec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 84.85%\n"
     ]
    }
   ],
   "source": [
    "# taxa de aprendizagem extremamente baixa, ou seja, os pesos são lentamente ajustados aos dados de treino\n",
    "amostras = 100\n",
    "ruido = 5\n",
    "testes = 500\n",
    "treino = 0.5\n",
    "taxa = 0.0001\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72388aa1",
   "metadata": {},
   "source": [
    "CASO 3 - Ajustado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d00966",
   "metadata": {},
   "source": [
    "O modelo ideial é quando os parametros são ajustados para que o modelo identifique as particularidades dos conjuntos sem que esteja sobreajustado à um conjunto especifico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26473e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acuracia Media: 96.60%\n"
     ]
    }
   ],
   "source": [
    "amostras = 100\n",
    "ruido = 5\n",
    "testes = 500\n",
    "treino = 0.8\n",
    "taxa = 0.1\n",
    "\n",
    "executar(n_amostras=amostras, tam_ruido=ruido, n_testes=testes, treino_teste=treino, taxa_aprend=taxa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
